{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anmihajlov/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "from tqdm import trange\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(path, batch_size, output_shape=(160, 160)):\n",
    "    cur_batch = []\n",
    "    for filename in sorted(list(os.listdir(path))):\n",
    "        filename_path = os.path.join(path, filename)\n",
    "        cur_image = imageio.imread(filename_path)\n",
    "        cur_image = resize(cur_image, output_shape, mode='reflect')\n",
    "        cur_batch.append(cur_image)\n",
    "        if len(cur_batch) == batch_size:\n",
    "            yield np.array(cur_batch)\n",
    "            cur_batch = []\n",
    "            \n",
    "    if cur_batch:\n",
    "        yield cur_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_filenames(model_dir):\n",
    "    files = os.listdir(model_dir)\n",
    "    meta_files = [s for s in files if s.endswith('.meta')]\n",
    "    if len(meta_files)==0:\n",
    "        raise ValueError('No meta file found in the model directory (%s)' % model_dir)\n",
    "    elif len(meta_files)>1:\n",
    "        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)\n",
    "    meta_file = meta_files[0]\n",
    "    # ckpt = tf.train.get_checkpoint_state(model_dir)\n",
    "    # if ckpt and ckpt.model_checkpoint_path:\n",
    "    #     ckpt_file = os.path.basename(ckpt.model_checkpoint_path)\n",
    "    #     return meta_file, ckpt_file\n",
    "    ckpt_file = \"model-20170512-110547.ckpt-250000\"\n",
    "    return meta_file, ckpt_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name='20170512-110547'):\n",
    "    model_path = os.path.join('model', model_name)\n",
    "    meta_file, ckpt_file = get_model_filenames(model_path)\n",
    "    sess = tf.Session()\n",
    "    saver = tf.train.import_meta_graph(os.path.join(model_path, meta_file))\n",
    "    saver.restore(sess, os.path.join(model_path, ckpt_file))\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The saved meta_graph is possibly from an older release:\n",
      "'model_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n",
      "INFO:tensorflow:Restoring parameters from model/20170512-110547/model-20170512-110547.ckpt-250000\n"
     ]
    }
   ],
   "source": [
    "sess = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n",
    "\n",
    "input_tensor = graph.get_tensor_by_name(\"input:0\")\n",
    "embeddings = graph.get_tensor_by_name(\"embeddings:0\")\n",
    "phase_train = graph.get_tensor_by_name(\"phase_train:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1583/1584 [42:08<00:01,  1.60s/it]"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d358d0092546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/img_align_celeba/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_COUNT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     img_emb = sess.run(embeddings, feed_dict={\n\u001b[1;32m      9\u001b[0m         \u001b[0minput_tensor\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "IMG_COUNT = 202599\n",
    "\n",
    "embs = []\n",
    "img_gen = generate_batches('data/img_align_celeba/', batch_size=BATCH_SIZE)\n",
    "for _ in trange(0, IMG_COUNT + BATCH_SIZE - 1, BATCH_SIZE):\n",
    "    images = next(img_gen)\n",
    "    img_emb = sess.run(embeddings, feed_dict={\n",
    "        input_tensor : images,\n",
    "        phase_train : False})\n",
    "    embs.append(img_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202599, 128)\n"
     ]
    }
   ],
   "source": [
    "embs_arr = np.vstack(embs)\n",
    "print(embs_arr.shape)\n",
    "np.save('embeddings', embs_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
